{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import cuda\n",
    "from time import time \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = nn.Sequential(*[nn.Linear(1, 500), \n",
    "                                     nn.ReLU(), \n",
    "                                     nn.Linear(500, 500),\n",
    "                                      nn.ReLU(), \n",
    "                                     nn.Linear(500, 500),\n",
    "                                      nn.ReLU(), \n",
    "                                     nn.Linear(500, 500),\n",
    "                                      nn.ReLU(), \n",
    "                                     nn.Linear(500, 500),\n",
    "                                      nn.ReLU(), \n",
    "                                     nn.Linear(500, 500),\n",
    "                                     nn.ReLU(), \n",
    "                                     nn.Linear(500, 10), \n",
    "                                     nn.Softmax(dim=1)])\n",
    "        self.cross_entropy = nn.CrossEntropyLoss(reduction='none')\n",
    "    \n",
    "    def regularizer(self):\n",
    "        reg = torch.tensor(0.).to(device)\n",
    "        for m in self.modules():\n",
    "            if hasattr(m, 'weight') and m.weight != None:\n",
    "                reg += m.weight.norm()**2\n",
    "        return reg\n",
    "            \n",
    "    def lossfn(self, ypred, ybatch):\n",
    "        cent = self.cross_entropy(ypred, ybatch.argmax(1)).mean()\n",
    "        loss = cent + self.regularizer()\n",
    "        return loss\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :  100\n",
      "Iteration :  200\n",
      "Iteration :  300\n",
      "Iteration :  400\n",
      "Iteration :  500\n",
      "Iteration :  600\n",
      "Iteration :  700\n",
      "Iteration :  800\n",
      "Iteration :  900\n",
      "Iteration : 1000\n",
      "Total time taken on cpu = 0.72449 minutes\n",
      "Iteration :  100\n",
      "Iteration :  200\n",
      "Iteration :  300\n",
      "Iteration :  400\n",
      "Iteration :  500\n",
      "Iteration :  600\n",
      "Iteration :  700\n",
      "Iteration :  800\n",
      "Iteration :  900\n",
      "Iteration : 1000\n",
      "Total time taken on cuda = 0.16357 minutes\n"
     ]
    }
   ],
   "source": [
    "cases = [torch.device('cpu'), torch.device('cuda:0')]\n",
    "for device in cases:\n",
    "    N = 10000\n",
    "    M = 256\n",
    "    x = torch.randn(N, 1).to(device)\n",
    "    y = np.random.randint(0, 10, size=(N,))\n",
    "    y = np.eye(10)[y]\n",
    "    y = torch.tensor(y, dtype=torch.float32).to(device)\n",
    "\n",
    "    net = Net().to(device)\n",
    "    optimizer = torch.optim.Adam(params=net.parameters(), lr=1e-3)\n",
    "\n",
    "    start = time()\n",
    "    for i in range(1000):\n",
    "        idx = np.random.randint(0, 100, M)\n",
    "        xbatch, ybatch = x[idx], y[idx]\n",
    "        optimizer.zero_grad()\n",
    "        ypred = net(xbatch)\n",
    "        loss = net.lossfn(ypred, ybatch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1)%100 == 0:\n",
    "            print(\"Iteration : %4d\"%(i+1))\n",
    "    stop = time()\n",
    "    total = (stop - start)/60.\n",
    "    print(\"Total time taken on %s = %.5f minutes\"%(device.type, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3193, 2.2896, 2.3170, 2.2531, 2.3002, 2.3144, 2.2820, 2.3348, 2.3258,\n",
       "        2.3194, 2.3288, 2.3074, 2.3115, 2.3194, 2.3115], device='cuda:0',\n",
       "       grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.cross_entropy(net(xbatch), ybatch.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
